
# SKF Product Assistant (Mini)

## ğŸš€ **Getting Started**

### **1. Prerequisites**

* Python **3.9+**
* Azure OpenAI **endpoint + key**
* Optional: Azure Cache for Redis (auto-fallback if missing)

---

### **2. Installation**

```bash
pip install -r requirements.txt
```

---

### **3. Configuration**

Create `.env` in the project root:

```
AZURE_OPENAI_DEPLOYMENT_NAME="gpt-40-mini"
AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com/"
AZURE_OPENAI_API_KEY="your-key-here"

# Optional - fallback to local mock if invalid
REDIS_CONNECTION_STRING="rediss://:password@host:port/0"
```

---

### **4. Running the App**

```bash
python app.py
```

Server runs at:

```
http://localhost:5000
```

---

## ğŸ§ª **How to Test the API**

Use Postman, Thunder Client, curl, or any HTTP client.

### **Endpoint**

```
POST http://localhost:5000/api/chat
```

---

### **Example 1 â€” Ask a product question (Q&A Intent)**

**Request**

```json
{
  "session_id": "user123",
  "message": "What is the limiting speed of 6205?"
}
```

**Response**

```
"The limiting speed of the 6205 is 18,000 r/min."
```

---

### **Example 2 â€” Follow-up question (Stateful Conversation)**

**Request**

```json
{
  "session_id": "user123",
  "message": "And what is its weight?"
}
```

**Response**

```
"The weight of the 6205 is 0.129 kg."
```

---

### **Example 3 â€” Provide feedback (Feedback Intent)**

**Request**

```json
{
  "session_id": "user123",
  "message": "The weight description is wrong, please correct it to 0.229"
}
```

**Response**

```
"The correction for the weight of the 6205 has been noted as 0.229 kg. Is there anything else you need?"
```

## ğŸ—ï¸ **Architecture & Components**

This application follows a **Service â†’ Plugin â†’ Orchestrator** pattern

### **Core Components**

### **`app.py` â€” API Gateway**

* Flask entry point.
* Handles incoming requests (`/api/chat`).
* Bridges synchronous HTTP calls with async Semantic Kernel execution.
* Validates requests and returns structured JSON responses.

---

### **`orchestrator.py` **

* Creates and manages the **Semantic Kernel** instance.
* Handles **Intent Routing**:

  * Q&A â†’ DatasheetPlugin
  * Feedback â†’ FeedbackPlugin
* Manages **conversation state** using chat history (Redis or local mock).

---

### **`config.py` â€” Config**

* Loads environment variables via `.env`.
* Stores Azure/OpenAI/Redis configuration.
* Prevents leaks by centralizing sensitive values.

---

## ğŸ”Œ **Plugins (The Agents)**

### **`plugins/datasheet_plugin.py` â€” Q&A Agent**

* Retrieves product attributes (e.g., *width*, *bore diameter*, *limiting speed*) from JSON datasheets.
* Implements **Redis caching**:

  * Cache HIT â†’ Returns instantly
  * Cache MISS â†’ Reads JSON and stores result

---

### **`plugins/feedback_plugin.py` â€” Feedback Agent**

* Stores user corrections or feedback.
* Saves feedback records (designation â†’ attribute â†’ note â†’ timestamp).

---

## ğŸ› ï¸ Services 

### **`services/data_manager.py`**

* Loads all JSON files inside `/data` automatically.
---

### **`services/redis_service.py`**

* Wrapper around Redis
  * If real Redis connection fails â†’ switches to **in-memory mock** so the app works.

---